# Application Configuration
NODE_ENV=development
PORT=3000
HOST=localhost

# GitHub Configuration
GITHUB_TOKEN=your-github-token-here
GITHUB_OWNER=your-github-owner
GITHUB_REPO=your-github-repo
GITHUB_ISSUE_NUMBER=

# JIRA Configuration (Input - for fetching data)
JIRA_URL=https://your-jira-instance.atlassian.net
JIRA_EMAIL=your-email@example.com
JIRA_API_TOKEN=your-jira-api-token
JIRA_PROJECT_KEY=YOUR_PROJECT_KEY
JIRA_FETCH_FIELDS=summary,description,customfield_10000
JIRA_MAX_RESULT=100
JIRA_TICKET_ID=

# JIRA Configuration (Output - for posting results)
JIRA_URL_OUTPUT=https://your-jira-instance.atlassian.net
JIRA_EMAIL_OUTPUT=your-email@example.com
JIRA_API_TOKEN_OUTPUT=your-jira-api-token
JIRA_SPACE_KEY_OUTPUT=MyTestSpace

# Confluence Configuration (for fetching data)
CONFLUENCE_URL=https://your-jira-instance.atlassian.net
CONFLUENCE_EMAIL=your-email@example.com
CONFLUENCE_API_TOKEN=your-confluence-api-token
CONFLUENCE_SPACE_KEY=MySpace
CONFLUENCE_MAX_PAGES=
CONFLUENCE_PAGE_LIMIT=50
# Suppress logging during page downloads (true/false, default: false)
CONFLUENCE_SILENT_MODE=false

# Confluence Upload Configuration (optional - for uploading to different account)
# If not provided, will use the same account as above
CONFLUENCE_UPLOAD_URL=
CONFLUENCE_UPLOAD_EMAIL=
CONFLUENCE_UPLOAD_API_TOKEN=
CONFLUENCE_UPLOAD_SPACE_KEY=

# OpenRouter AI Configuration
OPEN_ROUTER_API_KEY=your-openrouter-api-key
OPEN_ROUTER_API_URL=https://openrouter.ai/api/v1
OPEN_ROUTER_MODEL=google/gemini-2.0-flash-exp:free

# AWS Configuration (for S3)
AWS_ACCESS_KEY=
AWS_SECRET_KEY=
AWS_REGION=us-east-1
AWS_S3_BUCKET=

# AWS Bedrock Configuration (for LLM)
# Option 1: Use AWS Profile (Recommended - credentials from ~/.aws/credentials)
AWS_PROFILE=aws-profile
AWS_REGION=us-east-1
AWS_REGION_BEDROCK=us-east-1
# Option 2: Use Explicit Keys (Alternative)
AWS_ACCESS_KEY_BEDROCK=
AWS_SECRET_KEY_BEDROCK=
# Model Configuration
# Claude Sonnet 4.5 - using global inference profile
AWS_BEDROCK_MODEL=global.anthropic.claude-sonnet-4-5-20250929-v1:0
ANTHROPIC_MODEL=sonnet
CLAUDE_CODE_SUBAGENT_MODEL=sonnet
ANTHROPIC_DEFAULT_HAIKU_MODEL=global.anthropic.claude-sonnet-4-5-20250929-v1:0
ANTHROPIC_SMALL_FAST_MODEL=global.anthropic.claude-sonnet-4-5-20250929-v1:0
AWS_BEDROCK_EMBEDDING_MODEL=amazon.titan-embed-text-v2:0
# AI Service Selection: 1 = Use AWS Bedrock, 0 = Use OpenRouter
CLAUDE_CODE_USE_BEDROCK=1

# S3 Configuration
S3_BUCKET_NAME=

# Presidio Configuration (PII Detection)
PRESIDIO_ANALYZE_URL=http://localhost:5002/analyze
PRESIDIO_ANONYMIZE_URL=http://localhost:5001/anonymize

# Vector Store Configuration
VECTOR_STORE_TYPE=QDRANT
VECTOR_STORE_URL=http://127.0.0.1:6333

# Report Configuration
REPORT_FILE_PATH=coverage/ut-results.json
PROJECT_DOCUMENT_PATH=

# Docker Configuration
DOCKER_USERNAME=
DOCKER_PASSWORD=

# Usage Configuration
USE_FOR=GenerateTestCasesReport_API

# Requirement Analysis Configuration
# Available strategies: vector_db, llm, hybrid
ANALYSIS_STRATEGY=hybrid
# Maximum number of documents to return from vector search/LLM analysis
MAX_VECTOR_RESULTS=10
# Minimum similarity/relevance score (0.0 to 1.0)
# Lower = more results but less relevant, Higher = fewer but more relevant results
MIN_SIMILARITY_SCORE=0.7

# Analysis Path Configuration
# Current analysis folder path (format: YYYY-MM-DD-HH-MM-SS-Via-AI)
# This is used to construct the full analysis path: {SPACE_KEY}-Quality-Check-Via-AI/{TICKET_ID}-Via-AI/{CURRENT_ANALYSIS_PATH}
CURRENT_ANALYSIS_PATH=

SAVE_TO_FILE=true

# File Names Configuration (can be overridden)
JIRA_FILE_NAME=Jira.md
CONFLUENCE_FILE_NAME=Confluence.md
REQUIREMENTS_FILE_NAME=Requirements.md
ANALYSIS_REPORT_FILE_NAME=AnalysisReport.md

# Folder Naming Configuration
# Base folder suffix (default: Quality-Check-Via-AI)
BASE_FOLDER_SUFFIX=Quality-Check-Via-AI
# Ticket folder suffix (default: Via-AI)
TICKET_FOLDER_SUFFIX=Via-AI
# Timestamp folder suffix (default: Via-AI)
TIMESTAMP_FOLDER_SUFFIX=Via-AI

# Confluence Page Names Configuration
CONFLUENCE_ROOT_PAGE_SUFFIX=Quality-Check-Via-AI
CONFLUENCE_TICKET_PAGE_SUFFIX=Via-AI

# Note: Confluence page hierarchy structure:
# 1. Root: {SPACE_KEY}-Quality-Check-Via-AI (container for all reports)
# 2. Ticket: {TICKET_ID}-Via-AI (container for specific ticket reports)
# 3. Analysis: {CURRENT_ANALYSIS_PATH} (e.g., "2025-01-30-Via-AI" - the actual report page with content)
#
# Pages matching the above patterns or timestamp format will be automatically excluded
# when downloading Confluence content to prevent AI-generated reports from being
# re-analyzed in subsequent runs (prevents feedback loops)

# ===================================================================
# RAG SYSTEM CONFIGURATION (PostgreSQL + pgvector)
# ===================================================================

# Enable PostgreSQL Vector DB for storing Confluence documents
# Set to true to save Confluence pages to PostgreSQL with embeddings during fetch
# Set to false to only save to local files (default behavior)
USE_POSTGRES_VECTOR_DB=false

# PostgreSQL Database Configuration (Alternative naming convention)
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=******
DB_DATABASE=postgres-pgvector

# PostgreSQL Database Configuration (Legacy naming - kept for backward compatibility)
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=postgres-pgvector
DATABASE_USER=postgres
DATABASE_PASSWORD=*******


# OpenAI/OpenRouter Embeddings Configuration
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=

EMBEDDING_CONCURRENCY=20
EMBEDDING_BATCH_SIZE=100

# OpenRouter Configuration (if using OpenRouter instead of OpenAI)
OPENROUTER_SITE_URL=http://localhost
OPENROUTER_SITE_NAME=CheckUnitTestCases

# Confluence Indexer Configuration
INDEXER_BATCH_SIZE=10
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# JIRA Processor Configuration
JIRA_TOP_K=5
OUTPUT_DIR=./output

# Test Generation Configuration
TARGET_BRANCH=dev
