name: 'Check Unit Test Cases Quality'
description: 'Analyze unit test quality against JIRA requirements and generate comprehensive reports'
author: 'Vishal Gupta'

branding:
  icon: 'check-circle'
  color: 'green'

inputs:
  database_host:
    description: 'PostgreSQL database host'
    required: false
    default: 'localhost'
  database_port:
    description: 'PostgreSQL database port'
    required: false
    default: '5432'
  database_name:
    description: 'PostgreSQL database name'
    required: false
    default: 'postgres-pgvector'
  database_user:
    description: 'PostgreSQL database user'
    required: false
    default: 'postgres'
  database_password:
    description: 'PostgreSQL database password'
    required: false
    default: 'admin'
  jira_url:
    description: 'JIRA instance URL'
    required: true
  jira_email:
    description: 'JIRA user email'
    required: true
  jira_api_token:
    description: 'JIRA API token'
    required: true
  jira_ticket_id:
    description: 'JIRA ticket ID to analyze (e.g., BB-15690)'
    required: true
  jira_project_key:
    description: 'JIRA project key'
    required: true
  confluence_url:
    description: 'Confluence instance URL'
    required: true
  confluence_email:
    description: 'Confluence user email'
    required: true
  confluence_api_token:
    description: 'Confluence API token'
    required: true
  confluence_space_key:
    description: 'Confluence space key'
    required: true
  confluence_silent_mode:
    description: 'Suppress logging during Confluence page downloads (true/false)'
    required: false
    default: 'true'
  current_analysis_path:
    description: 'Specific analysis folder to use (optional, auto-generated if not provided)'
    required: false
    default: ''
  repository_url:
    description: 'Repository URL to clone for test analysis'
    required: true
  repository_branch:
    description: 'Branch name to clone'
    required: false
    default: 'main'
  target_branch:
    description: 'Target branch for generated unit test cases (default: main)'
    required: false
    default: 'main'
  save_to_file:
    description: 'Save analysis results to files (true/false)'
    required: false
    default: 'true'
  upload_to_confluence:
    description: 'Upload results to Confluence (true/false)'
    required: false
    default: 'true'
  minimum_score:
    description: 'Minimum acceptable test quality score (0-10)'
    required: false
    default: '6.0'
  aws_region_bedrock:
    description: 'AWS region for Bedrock service'
    required: false
    default: 'us-east-2'
  aws_access_key_bedrock:
    description: 'AWS access key for Bedrock authentication'
    required: true
  aws_secret_key_bedrock:
    description: 'AWS secret key for Bedrock authentication'
    required: true
  anthropic_model:
    description: 'Anthropic model name for Claude'
    required: false
    default: 'sonnet[1m]'
  claude_code_use_bedrock:
    description: 'Enable AWS Bedrock for Claude (1=enabled, 0=disabled)'
    required: false
    default: '1'
  base_folder_suffix:
    description: 'Base folder suffix for organizing analysis results'
    required: false
    default: 'Generate-Unit-Tests-Via-AI'
  confluence_root_page_suffix:
    description: 'Confluence root page suffix for organizing reports'
    required: false
    default: 'Generate-Unit-Tests-Via-AI'
  confluence_upload_url:
    description: 'Confluence instance URL for uploading results (if different from fetch URL)'
    required: false
    default: ''
  confluence_upload_email:
    description: 'Confluence user email for uploading results (if different from fetch email)'
    required: false
    default: ''
  confluence_upload_api_token:
    description: 'Confluence API token for uploading results (if different from fetch token)'
    required: false
    default: ''
  confluence_upload_space_key:
    description: 'Confluence space key for uploading results (if different from fetch space)'
    required: false
    default: ''
  docker_username:
    description: 'Docker registry username for authentication (optional - required for Presidio PII detection)'
    required: false
    default: ''
  docker_password:
    description: 'Docker registry password/token for authentication (optional - required for Presidio PII detection)'
    required: false
    default: ''
  openai_api_key:
    description: 'OpenAI API key for embeddings (required if USE_POSTGRES_VECTOR_DB is enabled)'
    required: false
    default: ''
  use_postgres_vector_db:
    description: 'Enable PostgreSQL Vector Database with pgvector for RAG-based Confluence fetching (true/false)'
    required: false
    default: 'true'

outputs:
  test_quality_score:
    description: 'Test quality score (0-10)'
    value: ${{ steps.extract_score.outputs.score }}
  analysis_path:
    description: 'Path to the analysis results folder'
    value: ${{ steps.extract_paths.outputs.analysis_path }}
  requirements_file:
    description: 'Path to the requirements file'
    value: ${{ steps.extract_paths.outputs.requirements_file }}
  result_file:
    description: 'Path to the result file'
    value: ${{ steps.extract_paths.outputs.result_file }}
  score_passed:
    description: 'Whether the score meets the minimum threshold (true/false)'
    value: ${{ steps.check_score.outputs.passed }}
  confluence_url:
    description: 'Confluence URL to the uploaded analysis report'
    value: ${{ steps.upload_confluence.outputs.confluence_url }}

runs:
  using: 'composite'
  steps:
    - name: Set analysis path
      id: set_analysis_path
      shell: bash
      run: |
        ANALYSIS_PATH="$(date +'%Y-%m-%d-%H-%M-%S')-Via-AI"
        echo "CURRENT_ANALYSIS_PATH=$ANALYSIS_PATH" >> $GITHUB_ENV
        echo "analysis_path=$ANALYSIS_PATH" >> $GITHUB_OUTPUT

        # Set ANALYSIS_FOLDER for use in prompts
        SPACE_KEY="${{ inputs.confluence_space_key }}"
        BASE_FOLDER_SUFFIX="${{ inputs.base_folder_suffix }}"
        ANALYSIS_FOLDER="${SPACE_KEY}-${BASE_FOLDER_SUFFIX}/${ANALYSIS_PATH}"
        echo "ANALYSIS_FOLDER=$ANALYSIS_FOLDER" >> $GITHUB_ENV

        echo "âœ… Analysis path set: $ANALYSIS_PATH"
        echo "âœ… Analysis folder set: $ANALYSIS_FOLDER"

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install dependencies
      shell: bash
      run: |
        cd ${{ github.action_path }}
        npm install
        npm install -g @anthropic-ai/claude-code

    - name: Setup PostgreSQL Database
      if: inputs.database_host == 'localhost' && inputs.docker_username != '' && inputs.docker_password != ''
      shell: bash
      run: |
        echo "ðŸ˜ Setting up PostgreSQL database..."

        # Pull PostgreSQL image with pgvector pre-installed
        echo "ðŸ“¥ Pulling PostgreSQL + pgvector image..."
        docker pull ankane/pgvector:latest -q 2>&1 | grep -v "Pulling\|Waiting\|Downloading\|Extracting\|Verifying\|Pull complete" || true

        # Start PostgreSQL container
        echo "ðŸš€ Starting PostgreSQL container..."
        docker run -d \
          --name postgres-pgvector \
          -e POSTGRES_USER="${{ inputs.database_user }}" \
          -e POSTGRES_PASSWORD="${{ inputs.database_password }}" \
          -e POSTGRES_DB="${{ inputs.database_name }}" \
          -p ${{ inputs.database_port }}:5432 \
          ankane/pgvector:latest

        # Wait for PostgreSQL to be ready
        echo "â³ Waiting for PostgreSQL to be ready..."
        sleep 10

        # Verify PostgreSQL is running
        echo "âœ… PostgreSQL setup complete"
        docker ps | grep postgres-pgvector

    - name: Docker login and start Presidio services
      if: inputs.docker_username != '' && inputs.docker_password != ''
      shell: bash
      run: |
        echo "ðŸ³ Logging in to Docker registry..."
        echo "${{ inputs.docker_password }}" | docker login -u "${{ inputs.docker_username }}" --password-stdin docker.io

        echo "ðŸ“¥ Pulling Presidio Docker images..."
        docker pull mcr.microsoft.com/presidio-analyzer:latest -q 2>&1 | grep -v "Pulling\|Waiting\|Downloading\|Extracting\|Verifying\|Pull complete" || true
        docker pull mcr.microsoft.com/presidio-anonymizer:latest -q 2>&1 | grep -v "Pulling\|Waiting\|Downloading\|Extracting\|Verifying\|Pull complete" || true

        echo "ðŸš€ Starting Presidio services..."
        docker run -d -p 5001:3000 --name presidio-anonymizer mcr.microsoft.com/presidio-anonymizer:latest
        docker run -d -p 5002:3000 --name presidio-analyzer mcr.microsoft.com/presidio-analyzer:latest

        echo "â³ Waiting for services to be ready..."
        sleep 10

        echo "ðŸ” Testing Presidio services availability..."

        # Wait up to 60 seconds for Presidio Analyzer to be ready
        MAX_WAIT=60
        ELAPSED=0
        ANALYZER_READY=false

        while [ $ELAPSED -lt $MAX_WAIT ]; do
          if curl -s -X POST http://localhost:5002/analyze \
            -H "Content-Type: application/json" \
            -d '{"text":"test","language":"en"}' \
            --max-time 5 > /dev/null 2>&1; then
            ANALYZER_READY=true
            echo "âœ… Presidio Analyzer is ready (took ${ELAPSED}s)"
            break
          fi
          echo "   â³ Waiting for Presidio Analyzer... (${ELAPSED}s/${MAX_WAIT}s)"
          sleep 5
          ELAPSED=$((ELAPSED + 5))
        done

        if [ "$ANALYZER_READY" = false ]; then
          echo "âš ï¸  Presidio Analyzer did not respond within ${MAX_WAIT}s - PII detection will use regex fallback"
        fi

        # Wait up to 60 seconds for Presidio Anonymizer to be ready
        ELAPSED=0
        ANONYMIZER_READY=false

        while [ $ELAPSED -lt $MAX_WAIT ]; do
          if curl -s -X POST http://localhost:5001/anonymize \
            -H "Content-Type: application/json" \
            -d '{"text":"test","anonymizers":{}}' \
            --max-time 5 > /dev/null 2>&1; then
            ANONYMIZER_READY=true
            echo "âœ… Presidio Anonymizer is ready (took ${ELAPSED}s)"
            break
          fi
          echo "   â³ Waiting for Presidio Anonymizer... (${ELAPSED}s/${MAX_WAIT}s)"
          sleep 5
          ELAPSED=$((ELAPSED + 5))
        done

        if [ "$ANONYMIZER_READY" = false ]; then
          echo "âš ï¸  Presidio Anonymizer did not respond within ${MAX_WAIT}s - PII detection will use regex fallback"
        fi

        if [ "$ANALYZER_READY" = true ] && [ "$ANONYMIZER_READY" = true ]; then
          echo "âœ… All Presidio services are ready and responding"
        else
          echo "âš ï¸  Some Presidio services are not ready - application will use regex-based PII detection"
        fi

        echo ""
        echo "ðŸ“Š Presidio containers status:"
        docker ps | grep presidio

    - name: Skip Presidio setup notification
      if: inputs.docker_username == '' || inputs.docker_password == ''
      shell: bash
      run: |
        echo "âš ï¸  Skipping Docker login and Presidio setup"
        echo "   Docker credentials not provided - PII detection will be disabled"
        echo "   To enable Presidio services, provide docker_username and docker_password inputs"

    - name: Clone repository for analysis
      shell: bash
      run: |
        cd ${{ github.action_path }}
        echo "ðŸ“¥ Cloning repository for test analysis..."

        # Use head_ref for PRs (gives branch name like BB-2244), ref_name for other events
        BRANCH="${{ github.head_ref || github.ref_name }}"
        echo "Branch to clone: $BRANCH"

        mkdir -p repo
        cd repo
        git clone --depth 1 --branch "$BRANCH" --single-branch https://x-access-token:${{ github.token }}@github.com/${{ github.repository }}.git .
        echo "âœ… Repository cloned successfully (branch: $BRANCH)"

    - name: Create .env file
      shell: bash
      run: |
        cd ${{ github.action_path }}
        cat > .env << EOF
        # Application Configuration
        NODE_ENV=production

        # JIRA Configuration
        JIRA_URL=${{ inputs.jira_url }}
        JIRA_EMAIL=${{ inputs.jira_email }}
        JIRA_API_TOKEN=${{ inputs.jira_api_token }}
        JIRA_TICKET_ID=${{ inputs.jira_ticket_id }}
        JIRA_PROJECT_KEY=${{ inputs.jira_project_key }}
        JIRA_FETCH_FIELDS=summary,description,customfield_10000
        JIRA_MAX_RESULT=100
        JIRA_FILE_NAME=Jira.md

        # Confluence Configuration (for fetching data)
        CONFLUENCE_URL=${{ inputs.confluence_url }}
        CONFLUENCE_EMAIL=${{ inputs.confluence_email }}
        CONFLUENCE_API_TOKEN=${{ inputs.confluence_api_token }}
        CONFLUENCE_SPACE_KEY=${{ inputs.confluence_space_key }}
        CONFLUENCE_SILENT_MODE=${{ inputs.confluence_silent_mode }}
        CONFLUENCE_MAX_PAGES=
        CONFLUENCE_PAGE_LIMIT=50
        CONFLUENCE_FILE_NAME=Confluence.md
        CONFLUENCE_RAG_FILE_NAME=Confluence-Rag.md

        # Confluence Upload Configuration (for uploading results)
        CONFLUENCE_UPLOAD_URL=${{ inputs.confluence_upload_url }}
        CONFLUENCE_UPLOAD_EMAIL=${{ inputs.confluence_upload_email }}
        CONFLUENCE_UPLOAD_API_TOKEN=${{ inputs.confluence_upload_api_token }}
        CONFLUENCE_UPLOAD_SPACE_KEY=${{ inputs.confluence_upload_space_key }}

        # Docker Configuration
        DOCKER_USERNAME=${{ inputs.docker_username }}
        DOCKER_PASSWORD=${{ inputs.docker_password }}

        # Presidio Configuration (PII Detection)
        PRESIDIO_ANALYZE_URL=http://localhost:5002/analyze
        PRESIDIO_ANONYMIZE_URL=http://localhost:5001/anonymize

        # Data Sanitization Configuration
        SANITIZE_PG_DATA=false

        # Analysis Configuration
        CURRENT_ANALYSIS_PATH=${{ env.CURRENT_ANALYSIS_PATH }}
        ANALYSIS_FOLDER=${{ env.ANALYSIS_FOLDER }}
        SAVE_TO_FILE=${{ inputs.save_to_file }}

        # File Names Configuration
        REQUIREMENTS_FILE_NAME=Requirements.md
        ANALYSIS_REPORT_FILE_NAME=AnalysisReport.md

        # Folder Naming Configuration
        BASE_FOLDER_SUFFIX=${{ inputs.base_folder_suffix }}
        TICKET_FOLDER_SUFFIX=Via-AI
        TIMESTAMP_FOLDER_SUFFIX=Via-AI

        # Confluence Page Names Configuration
        CONFLUENCE_ROOT_PAGE_SUFFIX=${{ inputs.confluence_root_page_suffix }}
        CONFLUENCE_TICKET_PAGE_SUFFIX=UT-Via-AI
        CONFLUENCE_TIMESTAMP_PAGE_SUFFIX=UT-Via-AI

        # RAG System Configuration (PostgreSQL + pgvector)
        USE_POSTGRES_VECTOR_DB=${{ inputs.use_postgres_vector_db }}
        DATABASE_HOST=${{ inputs.database_host }}
        DATABASE_PORT=${{ inputs.database_port }}
        DATABASE_NAME=${{ inputs.database_name }}
        DATABASE_USER=${{ inputs.database_user }}
        DATABASE_PASSWORD=${{ inputs.database_password }}

        # OpenAI Embeddings Configuration
        EMBEDDING_PROVIDER=openai
        OPENAI_API_KEY=${{ inputs.openai_api_key }}

        # Performance Configuration
        EMBEDDING_CONCURRENCY=50
        INDEXER_BATCH_SIZE=50
        CHUNK_SIZE=1000
        CHUNK_OVERLAP=200

        # Smart Filter Configuration
        USE_SMART_FILTER=true
        SMART_FILTER_MAX_PAGES=30
        SMART_FILTER_MIN_SCORE=0.3
        SMART_FILTER_USE_KEYWORDS=true
        SMART_FILTER_USE_TITLE=true
        SMART_FILTER_USE_LABELS=true
        SMART_FILTER_USE_COMPONENTS=true
        SMART_FILTER_DEBUG=false
        CHECK_PG_BEFORE_CONFLUENCE_FETCH=true

        EOF
        echo "âœ… Environment configuration created"

    - name: Test PostgreSQL Database Connection
      if: inputs.database_host == 'localhost' && inputs.docker_username != '' && inputs.docker_password != ''
      shell: bash
      run: |
        echo "ðŸ” Testing PostgreSQL database connection..."

        # Wait a bit more for PostgreSQL to fully initialize
        echo "â³ Waiting for PostgreSQL to fully initialize..."
        sleep 5

        # Test connection and run sample queries
        echo "ðŸ“Š Running sample queries..."
        docker exec postgres-pgvector psql -U "${{ inputs.database_user }}" -d "${{ inputs.database_name }}" -c "SELECT version();"

        echo ""
        echo "ðŸ“¦ Checking pgvector extension..."
        docker exec postgres-pgvector psql -U "${{ inputs.database_user }}" -d "${{ inputs.database_name }}" -c "CREATE EXTENSION IF NOT EXISTS vector;"
        docker exec postgres-pgvector psql -U "${{ inputs.database_user }}" -d "${{ inputs.database_name }}" -c "SELECT * FROM pg_extension WHERE extname = 'vector';"

        echo ""
        echo "âœ… Database connection test complete!"
        echo "ðŸ›‘ Exiting workflow for testing purposes..."

    - name: Step 1 - Fetch JIRA and Confluence data
      shell: bash
      run: |
        cd ${{ github.action_path }}
        echo "ðŸ”„ Fetching JIRA ticket and Confluence pages..."
        npm run start
        echo "âœ… Data fetched successfully"

    - name: Step 2 - Fetch Confluence with RAG
      if: inputs.use_postgres_vector_db == 'true'
      shell: bash
      run: |
        cd ${{ github.action_path }}
        echo "ðŸ”„ Fetching Confluence data using RAG-based approach..."
        npm run fetch-confluence-rag
        echo "âœ… Confluence RAG data fetched successfully"

    - name: Step 3 - Create Requirements document
      if: inputs.claude_code_use_bedrock == '1'
      shell: bash
      env:
        CLAUDE_CODE_USE_BEDROCK:  "1"
        AWS_REGION:               ${{ inputs.aws_region_bedrock }}
        ANTHROPIC_MODEL:          ${{ inputs.anthropic_model }}
        AWS_ACCESS_KEY_ID:        ${{ inputs.aws_access_key_bedrock }}
        AWS_SECRET_ACCESS_KEY:    ${{ inputs.aws_secret_key_bedrock }}
      run: |
        cd ${{ github.action_path }}
        echo "ðŸ“‹ Creating requirements document from JIRA and Confluence..."

        # Capture output from create-requirement-doc and extract cost
        OUTPUT1=$(npm run create-requirement-doc 2>&1)
        echo "$OUTPUT1"
        COST1=$(echo "$OUTPUT1" | grep "ðŸ’° Cost:" | sed 's/.*Cost: \$\([0-9.]*\).*/\1/')
        echo "COST_REQUIREMENT=$COST1" >> $GITHUB_ENV
        echo "âœ… Requirements document created (Cost: \$$COST1)"

        echo "ðŸ” Generating unit test cases..."

        # Capture output from generate-unit-testcases and extract cost
        OUTPUT2=$(npm run generate-unit-testcases 2>&1)
        echo "$OUTPUT2"
        COST2=$(echo "$OUTPUT2" | grep "ðŸ’° Cost:" | sed 's/.*Cost: \$\([0-9.]*\).*/\1/')
        echo "COST_GENERATION=$COST2" >> $GITHUB_ENV
        echo "âœ… Unit test cases generated successfully (Cost: \$$COST2)"

        # Calculate total cost
        TOTAL_COST=$(echo "$COST1 + $COST2" | bc)
        echo "TOTAL_CLAUDE_COST=$TOTAL_COST" >> $GITHUB_ENV
        echo "ðŸ’° Total Claude Cost: \$$TOTAL_COST (Model: ${{ inputs.anthropic_model }})"

    - name: Step 3.5 - List Analysis Folder Contents
      shell: bash
      run: |
        cd ${{ github.action_path }}
        echo "ðŸ“‚ Listing analysis folder contents..."

        SPACE_KEY="${{ inputs.confluence_space_key }}"
        BASE_FOLDER_SUFFIX="${{ inputs.base_folder_suffix }}"
        ANALYSIS_PATH="${{ env.CURRENT_ANALYSIS_PATH }}"

        ANALYSIS_FOLDER="${SPACE_KEY}-${BASE_FOLDER_SUFFIX}/${ANALYSIS_PATH}"

        # echo "ðŸ” Creating analysis folder if it doesn't exist..."
        # mkdir -p "$ANALYSIS_FOLDER"

        
        # echo "# Confluence RAG Content" > "$ANALYSIS_FOLDER/Confluence-Rag.md"
        # echo "This is test content for Confluence RAG." >> "$ANALYSIS_FOLDER/Confluence-Rag.md"
        
        # echo "# Confluence Content" > "$ANALYSIS_FOLDER/Confluence.md"
        # echo "This is test content for Confluence." >> "$ANALYSIS_FOLDER/Confluence.md"
        
        # echo "# JIRA Content" > "$ANALYSIS_FOLDER/Jira.md"
        # echo "This is test content for JIRA ticket." >> "$ANALYSIS_FOLDER/Jira.md"
        
        # echo "# PII Detection Report" > "$ANALYSIS_FOLDER/PII-Detection-Report.md"
        # echo "This is test content for PII detection." >> "$ANALYSIS_FOLDER/PII-Detection-Report.md"
        
        # echo "# Requirements RAG" > "$ANALYSIS_FOLDER/Requirements-Rag.md"
        # echo "This is test content for Requirements RAG." >> "$ANALYSIS_FOLDER/Requirements-Rag.md"
        
        if [ -d "$ANALYSIS_FOLDER" ]; then
          echo "âœ… Analysis folder: $ANALYSIS_FOLDER"
          ls -alh "$ANALYSIS_FOLDER"
        else
          echo "âŒ Analysis folder not found: $ANALYSIS_FOLDER"
          echo "ðŸ” Checking base directory..."
          ls -alh "${SPACE_KEY}-${BASE_FOLDER_SUFFIX}" || echo "Base directory not found"
        fi

    - name: Step 4 - Commit and Push Generated Tests
      id: commit_tests
      shell: bash
      run: |
        cd ${{ github.action_path }}/repo
        echo "ðŸ“ Committing all changes..."

        # Configure git
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"

        # Create branch name from ticket ID (trim whitespace)
        TICKET_ID=$(echo "${{ inputs.jira_ticket_id }}" | xargs)
        BRANCH_NAME="${TICKET_ID}-via-ai-$(date +%Y-%m-%d-%H-%M-%S)"
        echo "Preparing branch: $BRANCH_NAME"

        # Delete branch if it exists on remote
        if git ls-remote --heads origin "$BRANCH_NAME" | grep -q "$BRANCH_NAME"; then
          echo "âŒ Branch exists on remote, deleting it..."
          git push origin --delete "$BRANCH_NAME" || echo "Failed to delete remote branch, continuing..."
        fi

        # Create new branch
        echo "Creating new branch: $BRANCH_NAME"
        git checkout -b "$BRANCH_NAME"

        # Add all changes
        git add .

        # Check if there are changes to commit
        if git diff --cached --quiet; then
          echo ""
          echo "=========================================="
          echo "ðŸŽ‰ CONGRATULATIONS!"
          echo "=========================================="
          echo ""
          echo "âœ… All unit test cases are already properly created!"
          echo "âœ… The codebase has complete test coverage for this ticket."
          echo ""
          echo "ðŸ“‹ JIRA Ticket: ${{ inputs.jira_ticket_id }}"
          echo "ðŸŽ¯ No new tests required - feature is production-ready!"
          echo ""
          echo "=========================================="
          echo ""
          echo "branch_name=" >> $GITHUB_OUTPUT
          echo "branch_url=" >> $GITHUB_OUTPUT
          echo "has_changes=false" >> $GITHUB_OUTPUT
        else
          # Commit all changes
          git commit -m "test: generate unit tests for ${{ inputs.jira_ticket_id }}

          Generated comprehensive unit test cases using AI based on JIRA requirements and Confluence documentation.

          JIRA Ticket: ${{ inputs.jira_ticket_id }}
          Target Branch: ${{ inputs.target_branch }}

          ðŸ¤– Generated via GitHub Actions"

          # Push to remote
          echo "â¬†ï¸  Pushing branch to remote..."
          git push -u origin "$BRANCH_NAME"

          # Generate branch URL
          BRANCH_URL="https://github.com/${{ github.repository }}/tree/$BRANCH_NAME"

          echo "âœ… All changes committed and pushed to branch: $BRANCH_NAME"
          echo "branch_name=$BRANCH_NAME" >> $GITHUB_OUTPUT
          echo "branch_url=$BRANCH_URL" >> $GITHUB_OUTPUT
          echo "has_changes=true" >> $GITHUB_OUTPUT
        fi

    - name: Step 5 - Upload to Confluence with Branch URL
      id: upload_confluence
      shell: bash
      env:
        BRANCH_URL: ${{ steps.commit_tests.outputs.branch_url }}
        BRANCH_NAME: ${{ steps.commit_tests.outputs.branch_name }}
      run: |
        cd ${{ github.action_path }}
        echo "ðŸ“¤ Uploading results to Confluence with branch URL..."
        # npm run upload-requirements

        # Pass branch URL as environment variable to the upload script
        OUTPUT=$(npm run upload-requirements 2>&1)
        echo "$OUTPUT"

        # Extract Confluence URL from output (now returns full URL from service)
        CONFLUENCE_URL="$(echo "$OUTPUT" | grep -oP 'URL: \K.*' | head -1)"

        if [ -n "$CONFLUENCE_URL" ]; then
          echo "confluence_url=$CONFLUENCE_URL" >> $GITHUB_OUTPUT
          echo "âœ… Results uploaded to Confluence: $CONFLUENCE_URL"
          echo "âœ… Branch link included: ${{ steps.commit_tests.outputs.branch_url }}"
        else
          echo "confluence_url=" >> $GITHUB_OUTPUT
          echo "âœ… Results uploaded to Confluence"
        fi

    - name: Generate summary
      shell: bash
      run: |
        cd ${{ github.action_path }}
        BRANCH_NAME="${{ steps.commit_tests.outputs.branch_name }}"
        BRANCH_URL="${{ steps.commit_tests.outputs.branch_url }}"
        CONFLUENCE_URL="${{ steps.upload_confluence.outputs.confluence_url }}"
        ANALYSIS_FOLDER="${{ env.ANALYSIS_FOLDER }}"
        COST_REQUIREMENT="${{ env.COST_REQUIREMENT }}"
        COST_GENERATION="${{ env.COST_GENERATION }}"
        TOTAL_CLAUDE_COST="${{ env.TOTAL_CLAUDE_COST }}"

        echo "## ðŸŽ‰ Unit Test Generation Complete" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**JIRA Ticket:** ${{ inputs.jira_ticket_id }}" >> $GITHUB_STEP_SUMMARY
        echo "**Target Branch:** ${{ inputs.target_branch }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "âœ… **Status:** Tests generated and pushed successfully" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸŒ¿ Generated Branch" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch Name:** \`$BRANCH_NAME\`" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch URL:** [View Branch]($BRANCH_URL)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ”— Links" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # Add JIRA link
        JIRA_LINK="${{ inputs.jira_url }}/browse/${{ inputs.jira_ticket_id }}"
        echo "- **JIRA Ticket:** [${{ inputs.jira_ticket_id }}](${JIRA_LINK})" >> $GITHUB_STEP_SUMMARY

        # Add PR link if available
        if [ -n "${{ github.event.pull_request.html_url }}" ]; then
          echo "- **Pull Request:** [${{ github.event.pull_request.number }}](${{ github.event.pull_request.html_url }})" >> $GITHUB_STEP_SUMMARY
        fi

        # Add Confluence link if upload was successful
        if [ -n "$CONFLUENCE_URL" ]; then
          echo "- **Confluence Report:** [View Analysis Report](${CONFLUENCE_URL})" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ“ Analysis Folder" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        echo "$ANALYSIS_FOLDER" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ’° Claude Usage Cost" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Model:** ${{ inputs.anthropic_model }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Step | Cost |" >> $GITHUB_STEP_SUMMARY
        echo "|------|------|" >> $GITHUB_STEP_SUMMARY
        echo "| Requirements Generation | \$${COST_REQUIREMENT:-0.00} |" >> $GITHUB_STEP_SUMMARY
        echo "| Test Cases Generation | \$${COST_GENERATION:-0.00} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Total** | **\$${TOTAL_CLAUDE_COST:-0.00}** |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ“ Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "1. ðŸ” Review the generated tests in the branch" >> $GITHUB_STEP_SUMMARY
        echo "2. ðŸ”€ Create a Pull Request to merge into \`${{ inputs.target_branch }}\`" >> $GITHUB_STEP_SUMMARY
        echo "3. ðŸ“Š Check Confluence for detailed analysis report" >> $GITHUB_STEP_SUMMARY
        echo "4. âœ… Run tests locally to verify functionality" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "ðŸ¤– _Generated via GitHub Actions - Unit Test Generation Workflow_" >> $GITHUB_STEP_SUMMARY
