name: 'Check Unit Test Cases Quality'
description: 'Analyze unit test quality against JIRA requirements and generate comprehensive reports'
author: 'Vishal Gupta'

branding:
  icon: 'check-circle'
  color: 'green'

inputs:
  database_host:
    description: 'PostgreSQL database host'
    required: false
    default: 'localhost'
  database_port:
    description: 'PostgreSQL database port'
    required: false
    default: '5432'
  database_name:
    description: 'PostgreSQL database name'
    required: false
    default: 'postgres-pgvector'
  database_user:
    description: 'PostgreSQL database user'
    required: false
    default: 'postgres'
  database_password:
    description: 'PostgreSQL database password'
    required: false
    default: 'admin'
  jira_url:
    description: 'JIRA instance URL'
    required: true
  jira_email:
    description: 'JIRA user email'
    required: true
  jira_api_token:
    description: 'JIRA API token'
    required: true
  jira_ticket_id:
    description: 'JIRA ticket ID to analyze (e.g., BB-15690)'
    required: true
  jira_project_key:
    description: 'JIRA project key'
    required: true
  confluence_url:
    description: 'Confluence instance URL'
    required: true
  confluence_email:
    description: 'Confluence user email'
    required: true
  confluence_api_token:
    description: 'Confluence API token'
    required: true
  confluence_space_key:
    description: 'Confluence space key'
    required: true
  confluence_silent_mode:
    description: 'Suppress logging during Confluence page downloads (true/false)'
    required: false
    default: 'true'
  current_analysis_path:
    description: 'Specific analysis folder to use (optional, auto-generated if not provided)'
    required: false
    default: ''
  repository_url:
    description: 'Repository URL to clone for test analysis'
    required: true
  repository_branch:
    description: 'Branch name to clone'
    required: false
    default: 'main'
  target_branch:
    description: 'Target branch for generated unit test cases (default: dev)'
    required: false
    default: 'dev'
  save_to_file:
    description: 'Save analysis results to files (true/false)'
    required: false
    default: 'true'
  upload_to_confluence:
    description: 'Upload results to Confluence (true/false)'
    required: false
    default: 'true'
  minimum_score:
    description: 'Minimum acceptable test quality score (0-10)'
    required: false
    default: '6.0'
  aws_region_bedrock:
    description: 'AWS region for Bedrock service'
    required: false
    default: 'us-east-2'
  aws_access_key_bedrock:
    description: 'AWS access key for Bedrock authentication'
    required: true
  aws_secret_key_bedrock:
    description: 'AWS secret key for Bedrock authentication'
    required: true
  anthropic_model:
    description: 'Anthropic model name for Claude'
    required: false
    default: 'sonnet[1m]'
  anthropic_base_url:
    description: 'Anthropic API base URL (for GLM or custom endpoints)'
    required: false
    default: ''
  anthropic_auth_token:
    description: 'Anthropic API authentication token'
    required: false
    default: ''
  ai_type:
    description: 'AI provider type: 1 = claude_with_bedrock, 2 = claude_with_glm'
    required: false
    default: '1'
  base_folder_suffix:
    description: 'Base folder suffix for organizing analysis results'
    required: false
    default: 'Generate-Unit-Tests-Via-AI'
  confluence_root_page_suffix:
    description: 'Confluence root page suffix for organizing reports'
    required: false
    default: 'Generate-Unit-Tests-Via-AI'
  confluence_upload_url:
    description: 'Confluence instance URL for uploading results (if different from fetch URL)'
    required: false
    default: ''
  confluence_upload_email:
    description: 'Confluence user email for uploading results (if different from fetch email)'
    required: false
    default: ''
  confluence_upload_api_token:
    description: 'Confluence API token for uploading results (if different from fetch token)'
    required: false
    default: ''
  confluence_upload_space_key:
    description: 'Confluence space key for uploading results (if different from fetch space)'
    required: false
    default: ''
  docker_username:
    description: 'Docker registry username for authentication (optional - required for Presidio PII detection)'
    required: false
    default: ''
  docker_password:
    description: 'Docker registry password/token for authentication (optional - required for Presidio PII detection)'
    required: false
    default: ''
  openai_api_key:
    description: 'OpenAI API key for embeddings (required if USE_POSTGRES_VECTOR_DB is enabled)'
    required: false
    default: ''
  use_postgres_vector_db:
    description: 'Enable PostgreSQL Vector Database with pgvector for RAG-based Confluence fetching (true/false)'
    required: false
    default: 'true'
  embedding_dimensions:
    description: 'Embedding vector dimensions (1536 for OpenAI, 768 for Ollama nomic-embed-text)'
    required: false
    default: '1536'

outputs:
  test_quality_score:
    description: 'Test quality score (0-10)'
    value: ${{ steps.extract_score.outputs.score }}
  analysis_path:
    description: 'Path to the analysis results folder'
    value: ${{ steps.extract_paths.outputs.analysis_path }}
  requirements_file:
    description: 'Path to the requirements file'
    value: ${{ steps.extract_paths.outputs.requirements_file }}
  result_file:
    description: 'Path to the result file'
    value: ${{ steps.extract_paths.outputs.result_file }}
  score_passed:
    description: 'Whether the score meets the minimum threshold (true/false)'
    value: ${{ steps.check_score.outputs.passed }}
  confluence_url:
    description: 'Confluence URL to the uploaded analysis report'
    value: ${{ steps.upload_confluence.outputs.confluence_url }}
  pr_url:
    description: 'URL to the created/updated Pull Request'
    value: ${{ steps.create_pr.outputs.pr_url }}
  pr_number:
    description: 'Pull Request number'
    value: ${{ steps.create_pr.outputs.pr_number }}
  pr_action:
    description: 'PR action taken (created/updated/none)'
    value: ${{ steps.create_pr.outputs.pr_action }}

runs:
  using: 'composite'
  steps:
    - name: Set analysis path
      id: set_analysis_path
      shell: bash
      env:
        SPACE_KEY: ${{ inputs.confluence_space_key }}
        BASE_FOLDER_SUFFIX: ${{ inputs.base_folder_suffix }}
      run: |
        ANALYSIS_PATH="$(date +'%Y-%m-%d-%H-%M-%S')-Via-AI"
        echo "CURRENT_ANALYSIS_PATH=$ANALYSIS_PATH" >> $GITHUB_ENV
        echo "analysis_path=$ANALYSIS_PATH" >> $GITHUB_OUTPUT

        # Set ANALYSIS_FOLDER for use in prompts
        ANALYSIS_FOLDER="${SPACE_KEY}-${BASE_FOLDER_SUFFIX}/${ANALYSIS_PATH}"
        echo "ANALYSIS_FOLDER=$ANALYSIS_FOLDER" >> $GITHUB_ENV

        echo "âœ… Analysis path set: $ANALYSIS_PATH"
        echo "âœ… Analysis folder set: $ANALYSIS_FOLDER"

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install dependencies
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
      run: |
        cd "$ACTION_PATH"
        npm install
        npm install -g @anthropic-ai/claude-code

    - name: Restore Docker images from cache
      if: inputs.docker_username != '' && inputs.docker_password != ''
      id: docker-cache
      uses: actions/cache@v4
      with:
        path: /tmp/docker-images
        key: docker-images-pgvector-presidio-v1

    - name: Load Docker images from cache
      if: steps.docker-cache.outputs.cache-hit == 'true'
      shell: bash
      run: |
        echo "ðŸ“¦ Loading Docker images from cache..."
        if [ -f /tmp/docker-images/pgvector.tar ]; then
          docker load -i /tmp/docker-images/pgvector.tar
          echo "âœ… Loaded ankane/pgvector:latest from cache"
        fi
        if [ -f /tmp/docker-images/presidio-analyzer.tar ]; then
          docker load -i /tmp/docker-images/presidio-analyzer.tar
          echo "âœ… Loaded presidio-analyzer:latest from cache"
        fi
        if [ -f /tmp/docker-images/presidio-anonymizer.tar ]; then
          docker load -i /tmp/docker-images/presidio-anonymizer.tar
          echo "âœ… Loaded presidio-anonymizer:latest from cache"
        fi

    - name: Setup PostgreSQL Database
      if: inputs.database_host == 'localhost' && inputs.docker_username != '' && inputs.docker_password != ''
      shell: bash
      env:
        DB_USER: ${{ inputs.database_user }}
        DB_PASSWORD: ${{ inputs.database_password }}
        DB_NAME: ${{ inputs.database_name }}
        DB_PORT: ${{ inputs.database_port }}
        CACHE_HIT: ${{ steps.docker-cache.outputs.cache-hit }}
      run: |
        echo "ðŸ˜ Setting up PostgreSQL database..."

        # Pull PostgreSQL image only if not cached
        if [ "$CACHE_HIT" != "true" ] || ! docker image inspect ankane/pgvector:latest > /dev/null 2>&1; then
          echo "ðŸ“¥ Pulling PostgreSQL + pgvector image..."
          docker pull ankane/pgvector:latest -q 2>&1 | grep -v "Pulling\|Waiting\|Downloading\|Extracting\|Verifying\|Pull complete" || true
        else
          echo "âœ… Using cached PostgreSQL + pgvector image"
        fi

        # Start PostgreSQL container
        echo "ðŸš€ Starting PostgreSQL container..."
        docker run -d \
          --name postgres-pgvector \
          -e POSTGRES_USER="$DB_USER" \
          -e POSTGRES_PASSWORD="$DB_PASSWORD" \
          -e POSTGRES_DB="$DB_NAME" \
          -p "${DB_PORT}:5432" \
          ankane/pgvector:latest

        # Wait for PostgreSQL to be ready
        echo "â³ Waiting for PostgreSQL to be ready..."
        sleep 10

        # Verify PostgreSQL is running
        echo "âœ… PostgreSQL setup complete"
        docker ps | grep postgres-pgvector

    - name: Docker login and start Presidio services
      if: inputs.docker_username != '' && inputs.docker_password != ''
      shell: bash
      env:
        DOCKER_USER: ${{ inputs.docker_username }}
        DOCKER_PASS: ${{ inputs.docker_password }}
        CACHE_HIT: ${{ steps.docker-cache.outputs.cache-hit }}
      run: |
        echo "ðŸ³ Logging in to Docker registry..."
        echo "$DOCKER_PASS" | docker login -u "$DOCKER_USER" --password-stdin docker.io

        # Pull Presidio images only if not cached
        if [ "$CACHE_HIT" != "true" ] || ! docker image inspect mcr.microsoft.com/presidio-analyzer:latest > /dev/null 2>&1; then
          echo "ðŸ“¥ Pulling Presidio Docker images..."
          docker pull mcr.microsoft.com/presidio-analyzer:latest -q 2>&1 | grep -v "Pulling\|Waiting\|Downloading\|Extracting\|Verifying\|Pull complete" || true
          docker pull mcr.microsoft.com/presidio-anonymizer:latest -q 2>&1 | grep -v "Pulling\|Waiting\|Downloading\|Extracting\|Verifying\|Pull complete" || true
        else
          echo "âœ… Using cached Presidio Docker images"
        fi

        echo "ðŸš€ Starting Presidio services..."
        docker run -d -p 5001:3000 --name presidio-anonymizer mcr.microsoft.com/presidio-anonymizer:latest
        docker run -d -p 5002:3000 --name presidio-analyzer mcr.microsoft.com/presidio-analyzer:latest

        echo "â³ Waiting for services to be ready..."
        sleep 10

        echo "ðŸ” Testing Presidio services availability..."

        # Wait up to 60 seconds for Presidio Analyzer to be ready
        MAX_WAIT=60
        ELAPSED=0
        ANALYZER_READY=false

        while [ $ELAPSED -lt $MAX_WAIT ]; do
          if curl -s -X POST http://localhost:5002/analyze \
            -H "Content-Type: application/json" \
            -d '{"text":"test","language":"en"}' \
            --max-time 5 > /dev/null 2>&1; then
            ANALYZER_READY=true
            echo "âœ… Presidio Analyzer is ready (took ${ELAPSED}s)"
            break
          fi
          echo "   â³ Waiting for Presidio Analyzer... (${ELAPSED}s/${MAX_WAIT}s)"
          sleep 5
          ELAPSED=$((ELAPSED + 5))
        done

        if [ "$ANALYZER_READY" = false ]; then
          echo "âš ï¸  Presidio Analyzer did not respond within ${MAX_WAIT}s - PII detection will use regex fallback"
        fi

        # Wait up to 60 seconds for Presidio Anonymizer to be ready
        ELAPSED=0
        ANONYMIZER_READY=false

        while [ $ELAPSED -lt $MAX_WAIT ]; do
          if curl -s -X POST http://localhost:5001/anonymize \
            -H "Content-Type: application/json" \
            -d '{"text":"test","anonymizers":{}}' \
            --max-time 5 > /dev/null 2>&1; then
            ANONYMIZER_READY=true
            echo "âœ… Presidio Anonymizer is ready (took ${ELAPSED}s)"
            break
          fi
          echo "   â³ Waiting for Presidio Anonymizer... (${ELAPSED}s/${MAX_WAIT}s)"
          sleep 5
          ELAPSED=$((ELAPSED + 5))
        done

        if [ "$ANONYMIZER_READY" = false ]; then
          echo "âš ï¸  Presidio Anonymizer did not respond within ${MAX_WAIT}s - PII detection will use regex fallback"
        fi

        if [ "$ANALYZER_READY" = true ] && [ "$ANONYMIZER_READY" = true ]; then
          echo "âœ… All Presidio services are ready and responding"
        else
          echo "âš ï¸  Some Presidio services are not ready - application will use regex-based PII detection"
        fi

        echo ""
        echo "ðŸ“Š Presidio containers status:"
        docker ps | grep presidio

    - name: Save Docker images to cache
      if: inputs.docker_username != '' && inputs.docker_password != '' && steps.docker-cache.outputs.cache-hit != 'true'
      shell: bash
      run: |
        echo "ðŸ’¾ Saving Docker images to cache..."
        mkdir -p /tmp/docker-images

        if docker image inspect ankane/pgvector:latest > /dev/null 2>&1; then
          docker save ankane/pgvector:latest -o /tmp/docker-images/pgvector.tar
          echo "âœ… Saved ankane/pgvector:latest"
        fi

        if docker image inspect mcr.microsoft.com/presidio-analyzer:latest > /dev/null 2>&1; then
          docker save mcr.microsoft.com/presidio-analyzer:latest -o /tmp/docker-images/presidio-analyzer.tar
          echo "âœ… Saved presidio-analyzer:latest"
        fi

        if docker image inspect mcr.microsoft.com/presidio-anonymizer:latest > /dev/null 2>&1; then
          docker save mcr.microsoft.com/presidio-anonymizer:latest -o /tmp/docker-images/presidio-anonymizer.tar
          echo "âœ… Saved presidio-anonymizer:latest"
        fi

        echo "ðŸ“¦ Cache directory contents:"
        ls -lh /tmp/docker-images/

    - name: Skip Presidio setup notification
      if: inputs.docker_username == '' || inputs.docker_password == ''
      shell: bash
      run: |
        echo "âš ï¸  Skipping Docker login and Presidio setup"
        echo "   Docker credentials not provided - PII detection will be disabled"
        echo "   To enable Presidio services, provide docker_username and docker_password inputs"

    - name: Clone repository for analysis
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        BRANCH_REF: ${{ github.head_ref || github.ref_name }}
        GH_TOKEN: ${{ github.token }}
        REPO_NAME: ${{ github.repository }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ“¥ Cloning repository for test analysis..."

        echo "Branch to clone: $BRANCH_REF"

        mkdir -p repo
        cd repo
        git clone --depth 1 --branch "$BRANCH_REF" --single-branch "https://x-access-token:${GH_TOKEN}@github.com/${REPO_NAME}.git" .
        echo "âœ… Repository cloned successfully (branch: $BRANCH_REF)"

    - name: Create .env file
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        # JIRA Configuration
        INPUT_JIRA_URL: ${{ inputs.jira_url }}
        INPUT_JIRA_EMAIL: ${{ inputs.jira_email }}
        INPUT_JIRA_API_TOKEN: ${{ inputs.jira_api_token }}
        INPUT_JIRA_TICKET_ID: ${{ inputs.jira_ticket_id }}
        INPUT_JIRA_PROJECT_KEY: ${{ inputs.jira_project_key }}
        # Confluence Configuration
        INPUT_CONFLUENCE_URL: ${{ inputs.confluence_url }}
        INPUT_CONFLUENCE_EMAIL: ${{ inputs.confluence_email }}
        INPUT_CONFLUENCE_API_TOKEN: ${{ inputs.confluence_api_token }}
        INPUT_CONFLUENCE_SPACE_KEY: ${{ inputs.confluence_space_key }}
        INPUT_CONFLUENCE_SILENT_MODE: ${{ inputs.confluence_silent_mode }}
        # Confluence Upload Configuration
        INPUT_CONFLUENCE_UPLOAD_URL: ${{ inputs.confluence_upload_url }}
        INPUT_CONFLUENCE_UPLOAD_EMAIL: ${{ inputs.confluence_upload_email }}
        INPUT_CONFLUENCE_UPLOAD_API_TOKEN: ${{ inputs.confluence_upload_api_token }}
        INPUT_CONFLUENCE_UPLOAD_SPACE_KEY: ${{ inputs.confluence_upload_space_key }}
        # Docker Configuration
        INPUT_DOCKER_USERNAME: ${{ inputs.docker_username }}
        INPUT_DOCKER_PASSWORD: ${{ inputs.docker_password }}
        # Analysis Configuration
        INPUT_SAVE_TO_FILE: ${{ inputs.save_to_file }}
        INPUT_BASE_FOLDER_SUFFIX: ${{ inputs.base_folder_suffix }}
        INPUT_CONFLUENCE_ROOT_PAGE_SUFFIX: ${{ inputs.confluence_root_page_suffix }}
        # Database Configuration
        INPUT_USE_POSTGRES_VECTOR_DB: ${{ inputs.use_postgres_vector_db }}
        INPUT_DATABASE_HOST: ${{ inputs.database_host }}
        INPUT_DATABASE_PORT: ${{ inputs.database_port }}
        INPUT_DATABASE_NAME: ${{ inputs.database_name }}
        INPUT_DATABASE_USER: ${{ inputs.database_user }}
        INPUT_DATABASE_PASSWORD: ${{ inputs.database_password }}
        INPUT_OPENAI_API_KEY: ${{ inputs.openai_api_key }}
        # Anthropic/GLM Configuration
        INPUT_ANTHROPIC_MODEL: ${{ inputs.anthropic_model }}
        INPUT_ANTHROPIC_BASE_URL: ${{ inputs.anthropic_base_url }}
        INPUT_ANTHROPIC_AUTH_TOKEN: ${{ inputs.anthropic_auth_token }}
      run: |
        cd "$ACTION_PATH"
        cat > .env << EOF
        # Application Configuration
        NODE_ENV=production

        # JIRA Configuration
        JIRA_URL=$INPUT_JIRA_URL
        JIRA_EMAIL=$INPUT_JIRA_EMAIL
        JIRA_API_TOKEN=$INPUT_JIRA_API_TOKEN
        JIRA_TICKET_ID=$INPUT_JIRA_TICKET_ID
        JIRA_PROJECT_KEY=$INPUT_JIRA_PROJECT_KEY
        JIRA_FETCH_FIELDS=summary,description,customfield_10000
        JIRA_MAX_RESULT=100
        JIRA_FILE_NAME=Jira.md

        # Confluence Configuration (for fetching data)
        CONFLUENCE_URL=$INPUT_CONFLUENCE_URL
        CONFLUENCE_EMAIL=$INPUT_CONFLUENCE_EMAIL
        CONFLUENCE_API_TOKEN=$INPUT_CONFLUENCE_API_TOKEN
        CONFLUENCE_SPACE_KEY=$INPUT_CONFLUENCE_SPACE_KEY
        CONFLUENCE_SILENT_MODE=$INPUT_CONFLUENCE_SILENT_MODE
        CONFLUENCE_MAX_PAGES=
        CONFLUENCE_PAGE_LIMIT=50
        CONFLUENCE_FILE_NAME=Confluence.md
        CONFLUENCE_RAG_FILE_NAME=Confluence-Rag.md

        # Confluence Upload Configuration (for uploading results)
        CONFLUENCE_UPLOAD_URL=$INPUT_CONFLUENCE_UPLOAD_URL
        CONFLUENCE_UPLOAD_EMAIL=$INPUT_CONFLUENCE_UPLOAD_EMAIL
        CONFLUENCE_UPLOAD_API_TOKEN=$INPUT_CONFLUENCE_UPLOAD_API_TOKEN
        CONFLUENCE_UPLOAD_SPACE_KEY=$INPUT_CONFLUENCE_UPLOAD_SPACE_KEY

        # Docker Configuration
        DOCKER_USERNAME=$INPUT_DOCKER_USERNAME
        DOCKER_PASSWORD=$INPUT_DOCKER_PASSWORD

        # Presidio Configuration (PII Detection)
        PRESIDIO_ANALYZE_URL=http://localhost:5002/analyze
        PRESIDIO_ANONYMIZE_URL=http://localhost:5001/anonymize

        # Data Sanitization Configuration
        SANITIZE_PG_DATA=false

        # Analysis Configuration
        CURRENT_ANALYSIS_PATH=$CURRENT_ANALYSIS_PATH
        ANALYSIS_FOLDER=$ANALYSIS_FOLDER
        SAVE_TO_FILE=$INPUT_SAVE_TO_FILE

        # File Names Configuration
        REQUIREMENTS_FILE_NAME=Requirements.md
        ANALYSIS_REPORT_FILE_NAME=AnalysisReport.md

        # Folder Naming Configuration
        BASE_FOLDER_SUFFIX=$INPUT_BASE_FOLDER_SUFFIX
        TICKET_FOLDER_SUFFIX=Via-AI
        TIMESTAMP_FOLDER_SUFFIX=Via-AI

        # Confluence Page Names Configuration
        CONFLUENCE_ROOT_PAGE_SUFFIX=$INPUT_CONFLUENCE_ROOT_PAGE_SUFFIX
        CONFLUENCE_TICKET_PAGE_SUFFIX=UT-Via-AI
        CONFLUENCE_TIMESTAMP_PAGE_SUFFIX=UT-Via-AI

        # RAG System Configuration (PostgreSQL + pgvector)
        USE_POSTGRES_VECTOR_DB=$INPUT_USE_POSTGRES_VECTOR_DB
        DATABASE_HOST=$INPUT_DATABASE_HOST
        DATABASE_PORT=$INPUT_DATABASE_PORT
        DATABASE_NAME=$INPUT_DATABASE_NAME
        DATABASE_USER=$INPUT_DATABASE_USER
        DATABASE_PASSWORD=$INPUT_DATABASE_PASSWORD

        # OpenAI Embeddings Configuration
        EMBEDDING_PROVIDER=openai
        OPENAI_API_KEY=$INPUT_OPENAI_API_KEY

        # Performance Configuration
        EMBEDDING_CONCURRENCY=50
        INDEXER_BATCH_SIZE=50
        CHUNK_SIZE=1000
        CHUNK_OVERLAP=200

        # Smart Filter Configuration
        USE_SMART_FILTER=true
        SMART_FILTER_MAX_PAGES=30
        SMART_FILTER_MIN_SCORE=0.3
        SMART_FILTER_USE_KEYWORDS=true
        SMART_FILTER_USE_TITLE=true
        SMART_FILTER_USE_LABELS=true
        SMART_FILTER_USE_COMPONENTS=true
        SMART_FILTER_DEBUG=false
        CHECK_PG_BEFORE_CONFLUENCE_FETCH=true

        # Anthropic/GLM Configuration
        ANTHROPIC_MODEL=$INPUT_ANTHROPIC_MODEL
        ANTHROPIC_BASE_URL=$INPUT_ANTHROPIC_BASE_URL
        ANTHROPIC_AUTH_TOKEN=$INPUT_ANTHROPIC_AUTH_TOKEN

        EOF
        echo "âœ… Environment configuration created"

    - name: Test PostgreSQL Database Connection
      if: inputs.database_host == 'localhost' && inputs.docker_username != '' && inputs.docker_password != ''
      shell: bash
      env:
        DB_USER: ${{ inputs.database_user }}
        DB_NAME: ${{ inputs.database_name }}
      run: |
        echo "ðŸ” Testing PostgreSQL database connection..."

        # Wait a bit more for PostgreSQL to fully initialize
        echo "â³ Waiting for PostgreSQL to fully initialize..."
        sleep 5

        # Test connection and run sample queries
        echo "ðŸ“Š Running sample queries..."
        docker exec postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" -c "SELECT version();"

        echo ""
        echo "ðŸ“¦ Checking pgvector extension..."
        docker exec postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" -c "CREATE EXTENSION IF NOT EXISTS vector;"
        docker exec postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" -c "SELECT * FROM pg_extension WHERE extname = 'vector';"

        echo ""
        echo "âœ… Database connection test complete!"

    - name: Restore PostgreSQL data from cache
      if: inputs.use_postgres_vector_db == 'true' && inputs.database_host == 'localhost'
      id: pgdata-cache
      uses: actions/cache@v4
      with:
        path: /tmp/pgvector-data
        key: pgvector-data-${{ inputs.confluence_space_key }}-dim${{ inputs.embedding_dimensions }}-v1
        restore-keys: |
          pgvector-data-${{ inputs.confluence_space_key }}-dim${{ inputs.embedding_dimensions }}-

    - name: Load PostgreSQL data from cache
      if: steps.pgdata-cache.outputs.cache-hit == 'true' && inputs.database_host == 'localhost'
      shell: bash
      env:
        DB_USER: ${{ inputs.database_user }}
        DB_NAME: ${{ inputs.database_name }}
      run: |
        echo "ðŸ“¦ Restoring PostgreSQL data from cache..."
        if [ -f /tmp/pgvector-data/pgdump.sql ]; then
          # Restore the database dump
          docker exec -i postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" < /tmp/pgvector-data/pgdump.sql

          # Verify restoration
          DOC_COUNT=$(docker exec postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM confluence_documents;" 2>/dev/null || echo "0")
          DOC_COUNT=$(echo "$DOC_COUNT" | tr -d ' ')

          if [ "$DOC_COUNT" -gt 0 ]; then
            echo "âœ… Restored $DOC_COUNT documents from cache"
            echo "   Confluence fetch will be skipped!"
          else
            echo "âš ï¸  Cache restore completed but no documents found"
          fi
        else
          echo "âš ï¸  Cache file not found, will fetch from Confluence"
        fi

    - name: Step 1 - Fetch JIRA and Confluence data
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ”„ Fetching JIRA ticket and Confluence pages..."
        npm run start
        echo "âœ… Data fetched successfully"

    - name: Step 2 - Fetch Confluence with RAG
      if: inputs.use_postgres_vector_db == 'true'
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ”„ Fetching Confluence data using RAG-based approach..."
        npm run fetch-confluence-rag
        echo "âœ… Confluence RAG data fetched successfully"

    - name: Save PostgreSQL data to cache
      if: inputs.use_postgres_vector_db == 'true' && inputs.database_host == 'localhost' && steps.pgdata-cache.outputs.cache-hit != 'true'
      shell: bash
      env:
        DB_USER: ${{ inputs.database_user }}
        DB_NAME: ${{ inputs.database_name }}
      run: |
        echo "ðŸ’¾ Saving PostgreSQL data to cache..."
        mkdir -p /tmp/pgvector-data

        # Check if table exists and has data
        TABLE_EXISTS=$(docker exec postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'confluence_documents');" 2>/dev/null || echo "f")
        TABLE_EXISTS=$(echo "$TABLE_EXISTS" | tr -d ' ')

        if [ "$TABLE_EXISTS" = "t" ]; then
          DOC_COUNT=$(docker exec postgres-pgvector psql -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM confluence_documents;" 2>/dev/null || echo "0")
          DOC_COUNT=$(echo "$DOC_COUNT" | tr -d ' ')

          if [ "$DOC_COUNT" -gt 0 ]; then
            echo "ðŸ“Š Found $DOC_COUNT documents to cache"

            # Export the database
            docker exec postgres-pgvector pg_dump -U "$DB_USER" -d "$DB_NAME" --no-owner --no-acl > /tmp/pgvector-data/pgdump.sql

            DUMP_SIZE=$(du -h /tmp/pgvector-data/pgdump.sql | cut -f1)
            echo "âœ… PostgreSQL dump created: $DUMP_SIZE"
            echo "   Cache will be saved for next run"
          else
            echo "âš ï¸  No documents found, skipping cache save"
          fi
        else
          echo "âš ï¸  Table confluence_documents not found, skipping cache save"
        fi

    - name: Step 3 - Create Requirements document (GLM)
      if: inputs.ai_type == '2'
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        ANTHROPIC_BASE_URL:   ${{ inputs.anthropic_base_url }}
        ANTHROPIC_AUTH_TOKEN: ${{ inputs.anthropic_auth_token }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ¤– Using GLM API (ANTHROPIC_BASE_URL: $ANTHROPIC_BASE_URL)"
        echo "ðŸ“‹ Creating requirements document from JIRA and Confluence..."

        # Capture output from create-requirement-doc and extract cost
        OUTPUT1=$(npm run create-requirement-doc 2>&1)
        echo "$OUTPUT1"
        COST1=$(echo "$OUTPUT1" | grep "ðŸ’° Cost:" | sed 's/.*Cost: \$\([0-9.]*\).*/\1/')
        echo "COST_REQUIREMENT=$COST1" >> $GITHUB_ENV
        echo "âœ… Requirements document created (Cost: \$$COST1)"

        echo "ðŸ” Generating unit test cases..."

        # Capture output from generate-unit-testcases and extract cost
        OUTPUT2=$(npm run generate-unit-testcases 2>&1)
        echo "$OUTPUT2"
        COST2=$(echo "$OUTPUT2" | grep "ðŸ’° Cost:" | sed 's/.*Cost: \$\([0-9.]*\).*/\1/')
        echo "COST_GENERATION=$COST2" >> $GITHUB_ENV
        echo "âœ… Unit test cases generated successfully (Cost: \$$COST2)"

        # Calculate total cost
        TOTAL_COST=$(echo "$COST1 + $COST2" | bc)
        echo "TOTAL_CLAUDE_COST=$TOTAL_COST" >> $GITHUB_ENV
        echo "ðŸ’° Total Cost: \$$TOTAL_COST (Provider: GLM)"

    - name: Step 3 - Create Requirements document (Bedrock)
      if: inputs.ai_type == '1'
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        CLAUDE_CODE_USE_BEDROCK: "1"
        AWS_REGION:              ${{ inputs.aws_region_bedrock }}
        ANTHROPIC_MODEL:         ${{ inputs.anthropic_model }}
        AWS_ACCESS_KEY_ID:       ${{ inputs.aws_access_key_bedrock }}
        AWS_SECRET_ACCESS_KEY:   ${{ inputs.aws_secret_key_bedrock }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ¤– Using AWS Bedrock (Region: $AWS_REGION)"
        echo "ðŸ“‹ Creating requirements document from JIRA and Confluence..."

        # Capture output from create-requirement-doc and extract cost
        OUTPUT1=$(npm run create-requirement-doc 2>&1)
        echo "$OUTPUT1"
        COST1=$(echo "$OUTPUT1" | grep "ðŸ’° Cost:" | sed 's/.*Cost: \$\([0-9.]*\).*/\1/')
        echo "COST_REQUIREMENT=$COST1" >> $GITHUB_ENV
        echo "âœ… Requirements document created (Cost: \$$COST1)"

        echo "ðŸ” Generating unit test cases..."

        # Capture output from generate-unit-testcases and extract cost
        OUTPUT2=$(npm run generate-unit-testcases 2>&1)
        echo "$OUTPUT2"
        COST2=$(echo "$OUTPUT2" | grep "ðŸ’° Cost:" | sed 's/.*Cost: \$\([0-9.]*\).*/\1/')
        echo "COST_GENERATION=$COST2" >> $GITHUB_ENV
        echo "âœ… Unit test cases generated successfully (Cost: \$$COST2)"

        # Calculate total cost
        TOTAL_COST=$(echo "$COST1 + $COST2" | bc)
        echo "TOTAL_CLAUDE_COST=$TOTAL_COST" >> $GITHUB_ENV
        echo "ðŸ’° Total Claude Cost: \$$TOTAL_COST (Model: $ANTHROPIC_MODEL)"

    - name: Step 3.5 - List Analysis Folder Contents
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        SPACE_KEY: ${{ inputs.confluence_space_key }}
        BASE_FOLDER_SUFFIX: ${{ inputs.base_folder_suffix }}
        ANALYSIS_PATH: ${{ env.CURRENT_ANALYSIS_PATH }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ“‚ Listing analysis folder contents..."

        ANALYSIS_FOLDER="${SPACE_KEY}-${BASE_FOLDER_SUFFIX}/${ANALYSIS_PATH}"

        # echo "ðŸ” Creating analysis folder if it doesn't exist..."
        # mkdir -p "$ANALYSIS_FOLDER"

        
        # echo "# Confluence RAG Content" > "$ANALYSIS_FOLDER/Confluence-Rag.md"
        # echo "This is test content for Confluence RAG." >> "$ANALYSIS_FOLDER/Confluence-Rag.md"
        
        # echo "# Confluence Content" > "$ANALYSIS_FOLDER/Confluence.md"
        # echo "This is test content for Confluence." >> "$ANALYSIS_FOLDER/Confluence.md"
        
        # echo "# JIRA Content" > "$ANALYSIS_FOLDER/Jira.md"
        # echo "This is test content for JIRA ticket." >> "$ANALYSIS_FOLDER/Jira.md"
        
        # echo "# PII Detection Report" > "$ANALYSIS_FOLDER/PII-Detection-Report.md"
        # echo "This is test content for PII detection." >> "$ANALYSIS_FOLDER/PII-Detection-Report.md"
        
        # echo "# Requirements RAG" > "$ANALYSIS_FOLDER/Requirements-Rag.md"
        # echo "This is test content for Requirements RAG." >> "$ANALYSIS_FOLDER/Requirements-Rag.md"
        
        if [ -d "$ANALYSIS_FOLDER" ]; then
          echo "âœ… Analysis folder: $ANALYSIS_FOLDER"
          ls -alh "$ANALYSIS_FOLDER"
        else
          echo "âŒ Analysis folder not found: $ANALYSIS_FOLDER"
          echo "ðŸ” Checking base directory..."
          ls -alh "${SPACE_KEY}-${BASE_FOLDER_SUFFIX}" || echo "Base directory not found"
        fi

    - name: Step 4 - Commit and Push Generated Tests
      id: commit_tests
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        JIRA_TICKET_ID: ${{ inputs.jira_ticket_id }}
        TARGET_BRANCH: ${{ inputs.target_branch }}
        REPO_NAME: ${{ github.repository }}
      run: |
        cd "$ACTION_PATH/repo"
        echo "ðŸ“ Committing all changes..."

        # Configure git
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"

        # Create branch name from ticket ID (trim whitespace)
        TICKET_ID=$(echo "$JIRA_TICKET_ID" | xargs)
        BRANCH_NAME="${TICKET_ID}-via-ai-$(date +%Y-%m-%d-%H-%M-%S)"
        echo "Preparing branch: $BRANCH_NAME"

        # Delete branch if it exists on remote
        if git ls-remote --heads origin "$BRANCH_NAME" | grep -q "$BRANCH_NAME"; then
          echo "âŒ Branch exists on remote, deleting it..."
          git push origin --delete "$BRANCH_NAME" || echo "Failed to delete remote branch, continuing..."
        fi

        # Create new branch
        echo "Creating new branch: $BRANCH_NAME"
        git checkout -b "$BRANCH_NAME"

        # Add all changes
        git add .

        # Check if there are changes to commit
        if git diff --cached --quiet; then
          echo ""
          echo "=========================================="
          echo "ðŸŽ‰ CONGRATULATIONS!"
          echo "=========================================="
          echo ""
          echo "âœ… All unit test cases are already properly created!"
          echo "âœ… The codebase has complete test coverage for this ticket."
          echo ""
          echo "ðŸ“‹ JIRA Ticket: $JIRA_TICKET_ID"
          echo "ðŸŽ¯ No new tests required - feature is production-ready!"
          echo ""
          echo "=========================================="
          echo ""
          echo "branch_name=" >> $GITHUB_OUTPUT
          echo "branch_url=" >> $GITHUB_OUTPUT
          echo "has_changes=false" >> $GITHUB_OUTPUT
        else
          # Commit all changes
          git commit -m "test: generate unit tests for $JIRA_TICKET_ID

          Generated comprehensive unit test cases using AI based on JIRA requirements and Confluence documentation.

          JIRA Ticket: $JIRA_TICKET_ID
          Target Branch: $TARGET_BRANCH

          ðŸ¤– Generated via GitHub Actions"

          # Push to remote
          echo "â¬†ï¸  Pushing branch to remote..."
          git push -u origin "$BRANCH_NAME"

          # Generate branch URL
          BRANCH_URL="https://github.com/$REPO_NAME/tree/$BRANCH_NAME"

          echo "âœ… All changes committed and pushed to branch: $BRANCH_NAME"
          echo "branch_name=$BRANCH_NAME" >> $GITHUB_OUTPUT
          echo "branch_url=$BRANCH_URL" >> $GITHUB_OUTPUT
          echo "has_changes=true" >> $GITHUB_OUTPUT
        fi

    - name: Step 5 - Upload to Confluence with Branch URL
      id: upload_confluence
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        BRANCH_URL: ${{ steps.commit_tests.outputs.branch_url }}
        BRANCH_NAME: ${{ steps.commit_tests.outputs.branch_name }}
      run: |
        cd "$ACTION_PATH"
        echo "ðŸ“¤ Uploading results to Confluence with branch URL..."
        # npm run upload-requirements

        # Pass branch URL as environment variable to the upload script
        OUTPUT=$(npm run upload-requirements 2>&1)
        echo "$OUTPUT"

        # Extract Confluence URL from output (now returns full URL from service)
        CONFLUENCE_URL="$(echo "$OUTPUT" | grep -oP 'URL: \K.*' | head -1)"

        if [ -n "$CONFLUENCE_URL" ]; then
          echo "confluence_url=$CONFLUENCE_URL" >> $GITHUB_OUTPUT
          echo "âœ… Results uploaded to Confluence: $CONFLUENCE_URL"
          echo "âœ… Branch link included: $BRANCH_URL"
        else
          echo "confluence_url=" >> $GITHUB_OUTPUT
          echo "âœ… Results uploaded to Confluence"
        fi

    - name: Step 6 - Create Pull Request
      id: create_pr
      if: steps.commit_tests.outputs.has_changes == 'true'
      shell: bash
      env:
        GH_TOKEN: ${{ github.token }}
        ACTION_PATH: ${{ github.action_path }}
        BRANCH_NAME: ${{ steps.commit_tests.outputs.branch_name }}
        TARGET_BRANCH: ${{ inputs.target_branch }}
        JIRA_TICKET_ID: ${{ inputs.jira_ticket_id }}
        JIRA_URL: ${{ inputs.jira_url }}
        CONFLUENCE_URL: ${{ steps.upload_confluence.outputs.confluence_url }}
      run: |
        cd "$ACTION_PATH/repo"
        TICKET_ID=$(echo "$JIRA_TICKET_ID" | xargs)

        echo "ðŸ”€ Creating Pull Request..."
        echo "   Source: $BRANCH_NAME"
        echo "   Target: $TARGET_BRANCH"

        # Check if PR already exists
        EXISTING_PR=$(gh pr list --head "$BRANCH_NAME" --base "$TARGET_BRANCH" --json number,url --jq '.[0]' 2>/dev/null || echo "")

        if [ -n "$EXISTING_PR" ] && [ "$EXISTING_PR" != "null" ]; then
          PR_NUMBER=$(echo "$EXISTING_PR" | jq -r '.number')
          PR_URL=$(echo "$EXISTING_PR" | jq -r '.url')
          echo "ðŸ“ Pull Request already exists: #$PR_NUMBER"
          echo "pr_url=$PR_URL" >> $GITHUB_OUTPUT
          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          echo "pr_action=updated" >> $GITHUB_OUTPUT
        else
          # Create new PR
          PR_BODY="## Summary
        - Generated unit test cases for JIRA ticket: $TICKET_ID
        - AI-powered test generation based on JIRA requirements and Confluence documentation

        ## Test Plan
        - [ ] Review generated test cases
        - [ ] Run tests locally to verify functionality
        - [ ] Check test coverage

        ## Links
        - **JIRA Ticket:** [$TICKET_ID]($JIRA_URL/browse/$TICKET_ID)
        - **Confluence Report:** $CONFLUENCE_URL

        ---
        ðŸ¤– _Generated via GitHub Actions - Unit Test Generation Workflow_"

          PR_RESULT=$(gh pr create \
            --title "test($TICKET_ID): add AI-generated unit tests" \
            --body "$PR_BODY" \
            --base "$TARGET_BRANCH" \
            --head "$BRANCH_NAME" 2>&1) || true

          if echo "$PR_RESULT" | grep -q "https://"; then
            PR_URL=$(echo "$PR_RESULT" | grep -oE 'https://[^ ]+')
            PR_NUMBER=$(echo "$PR_URL" | grep -oE '[0-9]+$')
            echo "âœ… Pull Request created: $PR_URL"
            echo "pr_url=$PR_URL" >> $GITHUB_OUTPUT
            echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
            echo "pr_action=created" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ Could not create PR: $PR_RESULT"
            echo "pr_url=" >> $GITHUB_OUTPUT
            echo "pr_number=" >> $GITHUB_OUTPUT
            echo "pr_action=none" >> $GITHUB_OUTPUT
          fi
        fi

    - name: Skip PR Creation
      id: skip_pr
      if: steps.commit_tests.outputs.has_changes != 'true'
      shell: bash
      run: |
        echo "â„¹ï¸ No changes to commit, skipping PR creation"
        echo "pr_url=" >> $GITHUB_OUTPUT
        echo "pr_number=" >> $GITHUB_OUTPUT
        echo "pr_action=none" >> $GITHUB_OUTPUT

    - name: Generate summary
      shell: bash
      env:
        ACTION_PATH: ${{ github.action_path }}
        BRANCH_NAME: ${{ steps.commit_tests.outputs.branch_name }}
        BRANCH_URL: ${{ steps.commit_tests.outputs.branch_url }}
        CONFLUENCE_URL: ${{ steps.upload_confluence.outputs.confluence_url }}
        PR_URL: ${{ steps.create_pr.outputs.pr_url }}
        PR_NUMBER: ${{ steps.create_pr.outputs.pr_number }}
        PR_ACTION: ${{ steps.create_pr.outputs.pr_action }}
        JIRA_TICKET_ID: ${{ inputs.jira_ticket_id }}
        TARGET_BRANCH: ${{ inputs.target_branch }}
        JIRA_URL: ${{ inputs.jira_url }}
        ANTHROPIC_MODEL: ${{ inputs.anthropic_model }}
      run: |
        cd "$ACTION_PATH"
        ANALYSIS_FOLDER_VAL="$ANALYSIS_FOLDER"
        COST_REQUIREMENT_VAL="$COST_REQUIREMENT"
        COST_GENERATION_VAL="$COST_GENERATION"
        TOTAL_CLAUDE_COST_VAL="$TOTAL_CLAUDE_COST"

        echo "## ðŸŽ‰ Unit Test Generation Complete" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**JIRA Ticket:** $JIRA_TICKET_ID" >> $GITHUB_STEP_SUMMARY
        echo "**Target Branch:** $TARGET_BRANCH" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "âœ… **Status:** Tests generated and pushed successfully" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸŒ¿ Generated Branch" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch Name:** \`$BRANCH_NAME\`" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch URL:** [View Branch]($BRANCH_URL)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ”— Links" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # Add JIRA link (ensure absolute URL)
        JIRA_BASE="$JIRA_URL"
        # Add https:// if not present
        if [[ ! "$JIRA_BASE" =~ ^https?:// ]]; then
          JIRA_BASE="https://${JIRA_BASE}"
        fi
        JIRA_LINK="${JIRA_BASE}/browse/$JIRA_TICKET_ID"
        echo "- **JIRA Ticket:** [$JIRA_TICKET_ID](${JIRA_LINK})" >> $GITHUB_STEP_SUMMARY

        # Add PR link if available
        if [ -n "$PR_URL" ]; then
          if [ "$PR_ACTION" == "created" ]; then
            echo "- **Pull Request:** [#${PR_NUMBER}](${PR_URL}) (newly created)" >> $GITHUB_STEP_SUMMARY
          elif [ "$PR_ACTION" == "updated" ]; then
            echo "- **Pull Request:** [#${PR_NUMBER}](${PR_URL}) (existing)" >> $GITHUB_STEP_SUMMARY
          fi
        fi

        # Add Confluence link if upload was successful
        if [ -n "$CONFLUENCE_URL" ]; then
          echo "- **Confluence Report:** [View Analysis Report](${CONFLUENCE_URL})" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ“ Analysis Folder" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        echo "$ANALYSIS_FOLDER_VAL" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ’° Claude Usage Cost" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Model:** $ANTHROPIC_MODEL" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Step | Cost |" >> $GITHUB_STEP_SUMMARY
        echo "|------|------|" >> $GITHUB_STEP_SUMMARY
        echo "| Requirements Generation | \$${COST_REQUIREMENT_VAL:-0.00} |" >> $GITHUB_STEP_SUMMARY
        echo "| Test Cases Generation | \$${COST_GENERATION_VAL:-0.00} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Total** | **\$${TOTAL_CLAUDE_COST_VAL:-0.00}** |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### ðŸ“ Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "1. ðŸ” Review the generated tests in the branch" >> $GITHUB_STEP_SUMMARY
        if [ -n "$PR_URL" ]; then
          echo "2. ðŸ”€ Review and merge the Pull Request" >> $GITHUB_STEP_SUMMARY
        else
          echo "2. ðŸ”€ Create a Pull Request to merge into \`$TARGET_BRANCH\`" >> $GITHUB_STEP_SUMMARY
        fi
        echo "3. ðŸ“Š Check Confluence for detailed analysis report" >> $GITHUB_STEP_SUMMARY
        echo "4. âœ… Run tests locally to verify functionality" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "ðŸ¤– _Generated via GitHub Actions - Unit Test Generation Workflow_" >> $GITHUB_STEP_SUMMARY
